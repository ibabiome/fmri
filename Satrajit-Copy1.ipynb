{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import dataExtract_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat04799  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-04799-v7.mat')\n",
    "mat04820  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-04820-v7.mat')\n",
    "mat04847  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-04847-v7.mat')\n",
    "mat05675  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-05675-v7.mat')\n",
    "mat05680  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-05680-v7.mat')\n",
    "mat05710  = loadmat('/Users/satrajitmaitra/Downloads/Data/data-starplus-05710-v7.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mata04799 = dataExtract_latest.getMeta(mat04799)\n",
    "mata04820 = dataExtract_latest.getMeta(mat04820)\n",
    "mata04847 = dataExtract_latest.getMeta(mat04847)\n",
    "mata05675 = dataExtract_latest.getMeta(mat05675)\n",
    "mata05680 = dataExtract_latest.getMeta(mat05680)\n",
    "mata05710 = dataExtract_latest.getMeta(mat05710)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "info04799 = []\n",
    "sentence04799 = []\n",
    "picture04799 = []\n",
    "rawData04799 = mat04799['data']\n",
    "for i in range(mata04799['ntrials']):\n",
    "    infoOfGivenTrial = dataExtract_latest.getInfoFromList(mat04799,i)\n",
    "    info04799.append(infoOfGivenTrial)\n",
    "    if infoOfGivenTrial['cond'] == 2 or infoOfGivenTrial['cond'] == 3:\n",
    "        if infoOfGivenTrial['firstStimulus'] == 'P':\n",
    "            for j in range(16):\n",
    "                picture04799.append(rawData04799[i][0][j])\n",
    "            for j in range(16,32):\n",
    "                sentence04799.append(rawData04799[i][0][j])\n",
    "        elif infoOfGivenTrial['firstStimulus'] == 'S':\n",
    "            for j in range(16):\n",
    "                sentence04799.append(rawData04799[i][0][j])\n",
    "            for j in range(16,32):\n",
    "                picture04799.append(rawData04799[i][0][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data04799 = sentence04799+picture04799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels04799 = [1]*len(sentence04799) + [0]*len(picture04799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train04799, x_test04799 , y_train04799, y_test04799 = train_test_split(data04799,labels04799,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 500, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train04799, y_train04799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(x_test04799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.396, 0.448, 0.678, 0.52 , 0.412, 0.666, 0.726, 0.414, 0.544,\n",
       "       0.304, 0.444, 0.572, 0.312, 0.64 , 0.338, 0.562, 0.42 , 0.446,\n",
       "       0.476, 0.372, 0.398, 0.51 , 0.452, 0.634, 0.618, 0.362, 0.442,\n",
       "       0.608, 0.428, 0.494, 0.556, 0.704, 0.45 , 0.536, 0.448, 0.338,\n",
       "       0.466, 0.528, 0.39 , 0.376, 0.646, 0.398, 0.546, 0.368, 0.456,\n",
       "       0.544, 0.508, 0.688, 0.416, 0.57 , 0.538, 0.41 , 0.41 , 0.508,\n",
       "       0.66 , 0.544, 0.508, 0.272, 0.566, 0.396, 0.54 , 0.364, 0.472,\n",
       "       0.712, 0.488, 0.386, 0.564, 0.66 , 0.422, 0.484, 0.482, 0.43 ,\n",
       "       0.488, 0.514, 0.67 , 0.462, 0.492, 0.482, 0.712, 0.486, 0.268,\n",
       "       0.502, 0.432, 0.456, 0.438, 0.474, 0.44 , 0.408, 0.366, 0.46 ,\n",
       "       0.592, 0.564, 0.526, 0.558, 0.4  , 0.65 , 0.388, 0.636, 0.312,\n",
       "       0.566, 0.506, 0.68 , 0.462, 0.62 , 0.46 , 0.426, 0.422, 0.506,\n",
       "       0.554, 0.474, 0.524, 0.51 , 0.592, 0.666, 0.766, 0.358, 0.672,\n",
       "       0.51 , 0.392, 0.662, 0.308, 0.448, 0.57 , 0.544, 0.692, 0.65 ,\n",
       "       0.41 , 0.64 , 0.686, 0.658, 0.574, 0.56 , 0.31 , 0.73 , 0.532,\n",
       "       0.25 , 0.602, 0.652, 0.468, 0.686, 0.358, 0.564, 0.566, 0.474,\n",
       "       0.66 , 0.672, 0.382, 0.478, 0.598, 0.508, 0.472, 0.5  , 0.476,\n",
       "       0.45 , 0.592, 0.522, 0.382, 0.63 , 0.388, 0.488, 0.37 , 0.528,\n",
       "       0.508, 0.348, 0.368, 0.51 , 0.576, 0.358, 0.478, 0.478, 0.396,\n",
       "       0.638, 0.698, 0.454, 0.5  , 0.342, 0.552, 0.566, 0.7  , 0.384,\n",
       "       0.59 , 0.558, 0.696, 0.36 , 0.558, 0.606, 0.338, 0.554, 0.472,\n",
       "       0.356, 0.734, 0.406, 0.418, 0.63 , 0.664, 0.392, 0.338, 0.434,\n",
       "       0.718, 0.686, 0.502, 0.618, 0.438, 0.342, 0.492, 0.59 , 0.504,\n",
       "       0.346, 0.524, 0.418, 0.572, 0.46 , 0.426, 0.38 , 0.382, 0.46 ,\n",
       "       0.59 , 0.438, 0.526, 0.562, 0.528, 0.526, 0.438, 0.664, 0.51 ,\n",
       "       0.67 , 0.67 , 0.396, 0.52 , 0.52 , 0.372, 0.51 , 0.414, 0.526,\n",
       "       0.598, 0.416, 0.382, 0.446, 0.54 , 0.388, 0.532, 0.45 , 0.512,\n",
       "       0.536, 0.502, 0.534, 0.282, 0.588, 0.604, 0.748, 0.53 , 0.534,\n",
       "       0.418, 0.562, 0.73 , 0.626])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.396,\n",
       " 0.448,\n",
       " 0.678,\n",
       " 0.52,\n",
       " 0.412,\n",
       " 0.666,\n",
       " 0.726,\n",
       " 0.414,\n",
       " 0.544,\n",
       " 0.304,\n",
       " 0.444,\n",
       " 0.572,\n",
       " 0.312,\n",
       " 0.64,\n",
       " 0.338,\n",
       " 0.562,\n",
       " 0.42,\n",
       " 0.446,\n",
       " 0.476,\n",
       " 0.372,\n",
       " 0.398,\n",
       " 0.51,\n",
       " 0.452,\n",
       " 0.634,\n",
       " 0.618,\n",
       " 0.362,\n",
       " 0.442,\n",
       " 0.608,\n",
       " 0.428,\n",
       " 0.494,\n",
       " 0.556,\n",
       " 0.704,\n",
       " 0.45,\n",
       " 0.536,\n",
       " 0.448,\n",
       " 0.338,\n",
       " 0.466,\n",
       " 0.528,\n",
       " 0.39,\n",
       " 0.376,\n",
       " 0.646,\n",
       " 0.398,\n",
       " 0.546,\n",
       " 0.368,\n",
       " 0.456,\n",
       " 0.544,\n",
       " 0.508,\n",
       " 0.688,\n",
       " 0.416,\n",
       " 0.57,\n",
       " 0.538,\n",
       " 0.41,\n",
       " 0.41,\n",
       " 0.508,\n",
       " 0.66,\n",
       " 0.544,\n",
       " 0.508,\n",
       " 0.272,\n",
       " 0.566,\n",
       " 0.396,\n",
       " 0.54,\n",
       " 0.364,\n",
       " 0.472,\n",
       " 0.712,\n",
       " 0.488,\n",
       " 0.386,\n",
       " 0.564,\n",
       " 0.66,\n",
       " 0.422,\n",
       " 0.484,\n",
       " 0.482,\n",
       " 0.43,\n",
       " 0.488,\n",
       " 0.514,\n",
       " 0.67,\n",
       " 0.462,\n",
       " 0.492,\n",
       " 0.482,\n",
       " 0.712,\n",
       " 0.486,\n",
       " 0.268,\n",
       " 0.502,\n",
       " 0.432,\n",
       " 0.456,\n",
       " 0.438,\n",
       " 0.474,\n",
       " 0.44,\n",
       " 0.408,\n",
       " 0.366,\n",
       " 0.46,\n",
       " 0.592,\n",
       " 0.564,\n",
       " 0.526,\n",
       " 0.558,\n",
       " 0.4,\n",
       " 0.65,\n",
       " 0.388,\n",
       " 0.636,\n",
       " 0.312,\n",
       " 0.566,\n",
       " 0.506,\n",
       " 0.68,\n",
       " 0.462,\n",
       " 0.62,\n",
       " 0.46,\n",
       " 0.426,\n",
       " 0.422,\n",
       " 0.506,\n",
       " 0.554,\n",
       " 0.474,\n",
       " 0.524,\n",
       " 0.51,\n",
       " 0.592,\n",
       " 0.666,\n",
       " 0.766,\n",
       " 0.358,\n",
       " 0.672,\n",
       " 0.51,\n",
       " 0.392,\n",
       " 0.662,\n",
       " 0.308,\n",
       " 0.448,\n",
       " 0.57,\n",
       " 0.544,\n",
       " 0.692,\n",
       " 0.65,\n",
       " 0.41,\n",
       " 0.64,\n",
       " 0.686,\n",
       " 0.658,\n",
       " 0.574,\n",
       " 0.56,\n",
       " 0.31,\n",
       " 0.73,\n",
       " 0.532,\n",
       " 0.25,\n",
       " 0.602,\n",
       " 0.652,\n",
       " 0.468,\n",
       " 0.686,\n",
       " 0.358,\n",
       " 0.564,\n",
       " 0.566,\n",
       " 0.474,\n",
       " 0.66,\n",
       " 0.672,\n",
       " 0.382,\n",
       " 0.478,\n",
       " 0.598,\n",
       " 0.508,\n",
       " 0.472,\n",
       " 0.5,\n",
       " 0.476,\n",
       " 0.45,\n",
       " 0.592,\n",
       " 0.522,\n",
       " 0.382,\n",
       " 0.63,\n",
       " 0.388,\n",
       " 0.488,\n",
       " 0.37,\n",
       " 0.528,\n",
       " 0.508,\n",
       " 0.348,\n",
       " 0.368,\n",
       " 0.51,\n",
       " 0.576,\n",
       " 0.358,\n",
       " 0.478,\n",
       " 0.478,\n",
       " 0.396,\n",
       " 0.638,\n",
       " 0.698,\n",
       " 0.454,\n",
       " 0.5,\n",
       " 0.342,\n",
       " 0.552,\n",
       " 0.566,\n",
       " 0.7,\n",
       " 0.384,\n",
       " 0.59,\n",
       " 0.558,\n",
       " 0.696,\n",
       " 0.36,\n",
       " 0.558,\n",
       " 0.606,\n",
       " 0.338,\n",
       " 0.554,\n",
       " 0.472,\n",
       " 0.356,\n",
       " 0.734,\n",
       " 0.406,\n",
       " 0.418,\n",
       " 0.63,\n",
       " 0.664,\n",
       " 0.392,\n",
       " 0.338,\n",
       " 0.434,\n",
       " 0.718,\n",
       " 0.686,\n",
       " 0.502,\n",
       " 0.618,\n",
       " 0.438,\n",
       " 0.342,\n",
       " 0.492,\n",
       " 0.59,\n",
       " 0.504,\n",
       " 0.346,\n",
       " 0.524,\n",
       " 0.418,\n",
       " 0.572,\n",
       " 0.46,\n",
       " 0.426,\n",
       " 0.38,\n",
       " 0.382,\n",
       " 0.46,\n",
       " 0.59,\n",
       " 0.438,\n",
       " 0.526,\n",
       " 0.562,\n",
       " 0.528,\n",
       " 0.526,\n",
       " 0.438,\n",
       " 0.664,\n",
       " 0.51,\n",
       " 0.67,\n",
       " 0.67,\n",
       " 0.396,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.372,\n",
       " 0.51,\n",
       " 0.414,\n",
       " 0.526,\n",
       " 0.598,\n",
       " 0.416,\n",
       " 0.382,\n",
       " 0.446,\n",
       " 0.54,\n",
       " 0.388,\n",
       " 0.532,\n",
       " 0.45,\n",
       " 0.512,\n",
       " 0.536,\n",
       " 0.502,\n",
       " 0.534,\n",
       " 0.282,\n",
       " 0.588,\n",
       " 0.604,\n",
       " 0.748,\n",
       " 0.53,\n",
       " 0.534,\n",
       " 0.418,\n",
       " 0.562,\n",
       " 0.73,\n",
       " 0.626]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] > 0.5:\n",
    "        predicted_classes.append(1)\n",
    "    else:\n",
    "        predicted_classes.append(0)\n",
    "\n",
    "accuracy04799 = metrics.accuracy_score(y_test04799, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66015625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy04799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
